{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://JackF-Win10.InformativeResearch.com:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x201e06df548>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing the diabetes dataset from https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28original%29 in the attempt to predict malignant or benign tumors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target variable has two possible outcomes\n",
    "### 1.Malignant Tumor (reflected as 4 in original dataset)\n",
    "### 2. Benign Tumor (reflected as 2 in original dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For context, malignant tumors are seen as more dangerous than benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(r'C:\\Users\\jackf\\Desktop\\Python\\Test Data\\breast-cancer-wisconsin.data.csv',\n",
    "                    header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data set is: 740 rows x 11 columns\n"
     ]
    }
   ],
   "source": [
    "#data set size\n",
    "print(f\"The size of the data set is: {df.count()} rows x {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- ClumpThickness: string (nullable = true)\n",
      " |-- UnifromityCellSize: string (nullable = true)\n",
      " |-- UniformityCellShape: string (nullable = true)\n",
      " |-- Adhesion: string (nullable = true)\n",
      " |-- EpithelialCellSize: string (nullable = true)\n",
      " |-- BareNuclei: string (nullable = true)\n",
      " |-- BlandChromatin: string (nullable = true)\n",
      " |-- NormalNuclei: string (nullable = true)\n",
      " |-- Mitoses: string (nullable = true)\n",
      " |-- Target: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can remove the ID column as it's not relevant\n",
    "df = df.drop(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the target for clarity, change Malignant to 1 and Benign to 0\n",
    "df = df.withColumn(\"Target\", F.when(F.col(\"Target\") == 4,1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate the distribution of data\n",
    "count_pos = df.where(F.col(\"Target\") == 1).count()\n",
    "count_neg = df.where(F.col(\"Target\") == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of malignant cases are 253 or 34.19% \n",
      "The number of benign cases are 487 or 65.81%\n"
     ]
    }
   ],
   "source": [
    "#Display the counts and percentage\n",
    "print(f\"The number of malignant cases are {count_pos} or {round((count_pos/df.count())*100,2)}% \\nThe number of benign cases are {count_neg} or {round((count_neg)/(df.count())*100,2)}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ClumpThickness: string (nullable = true)\n",
      " |-- UnifromityCellSize: string (nullable = true)\n",
      " |-- UniformityCellShape: string (nullable = true)\n",
      " |-- Adhesion: string (nullable = true)\n",
      " |-- EpithelialCellSize: string (nullable = true)\n",
      " |-- BareNuclei: string (nullable = true)\n",
      " |-- BlandChromatin: string (nullable = true)\n",
      " |-- NormalNuclei: string (nullable = true)\n",
      " |-- Mitoses: string (nullable = true)\n",
      " |-- Target: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ClumpThickness: double (nullable = true)\n",
      " |-- UnifromityCellSize: double (nullable = true)\n",
      " |-- UniformityCellShape: double (nullable = true)\n",
      " |-- Adhesion: double (nullable = true)\n",
      " |-- EpithelialCellSize: double (nullable = true)\n",
      " |-- BareNuclei: double (nullable = true)\n",
      " |-- BlandChromatin: double (nullable = true)\n",
      " |-- NormalNuclei: double (nullable = true)\n",
      " |-- Mitoses: double (nullable = true)\n",
      " |-- Target: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    df = df.withColumn(col, F.col(col).cast(\"double\"))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dive into the relationship of the features with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClumpThickness has a pearson score of 0.7063781135590114\n",
      "UnifromityCellSize has a pearson score of 0.8167100574055357\n",
      "UniformityCellShape has a pearson score of 0.8155992074898362\n",
      "Adhesion has a pearson score of 0.6910229647315073\n",
      "EpithelialCellSize has a pearson score of 0.6796918453202054\n",
      "BareNuclei has a pearson score of 0.8166268113918972\n",
      "BlandChromatin has a pearson score of 0.7647049652976591\n",
      "NormalNuclei has a pearson score of 0.6958434231476123\n",
      "Target has a pearson score of 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    t = df.corr(\"Target\", i)\n",
    "    \n",
    "    if t > .6:\n",
    "        print(f\"{i} has a pearson score of {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = df.select(\"ClumpThickness\",\n",
    "                              \"UnifromityCellSize\",\n",
    "                              \"UniformityCellShape\",\n",
    "                              \"Adhesion\",\n",
    "                              \"EpithelialCellSize\",\n",
    "                              \"BareNuclei\",\n",
    "                               \"BlandChromatin\",\n",
    "                              \"NormalNuclei\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+-------------------+--------+------------------+----------+--------------+------------+\n",
      "|ClumpThickness|UnifromityCellSize|UniformityCellShape|Adhesion|EpithelialCellSize|BareNuclei|BlandChromatin|NormalNuclei|\n",
      "+--------------+------------------+-------------------+--------+------------------+----------+--------------+------------+\n",
      "|           5.0|               1.0|                1.0|     1.0|               2.0|       1.0|           3.0|         1.0|\n",
      "|           5.0|               4.0|                4.0|     5.0|               7.0|      10.0|           3.0|         2.0|\n",
      "+--------------+------------------+-------------------+--------+------------------+----------+--------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_features.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize VectorAssembler to place features into a single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=selected_features.columns,\n",
    "                           outputCol='features',\n",
    "                           handleInvalid='skip')\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ClumpThickness: double (nullable = true)\n",
      " |-- UnifromityCellSize: double (nullable = true)\n",
      " |-- UniformityCellShape: double (nullable = true)\n",
      " |-- Adhesion: double (nullable = true)\n",
      " |-- EpithelialCellSize: double (nullable = true)\n",
      " |-- BareNuclei: double (nullable = true)\n",
      " |-- BlandChromatin: double (nullable = true)\n",
      " |-- NormalNuclei: double (nullable = true)\n",
      " |-- Mitoses: double (nullable = true)\n",
      " |-- Target: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|features                          |\n",
      "+----------------------------------+\n",
      "|[5.0,1.0,1.0,1.0,2.0,1.0,3.0,1.0] |\n",
      "|[5.0,4.0,4.0,5.0,7.0,10.0,3.0,2.0]|\n",
      "|[3.0,1.0,1.0,1.0,2.0,2.0,3.0,1.0] |\n",
      "+----------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"features\").show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "standardScaler = StandardScaler().setInputCol(\"features\").setOutputCol(\"scaled_features\")\n",
    "df = standardScaler.fit(df).transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|scaled_features                                                                                                                                           |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.7772572343497226,0.3259878010202712,0.33426212675591777,0.3485101727570922,0.9012476431727784,0.2751797395931149,1.2230607806221265,0.3284538054668826]|\n",
      "|[1.7772572343497226,1.3039512040810848,1.337048507023671,1.742550863785461,3.154366751104724,2.751797395931149,1.2230607806221265,0.6569076109337652]     |\n",
      "|[1.0663543406098335,0.3259878010202712,0.33426212675591777,0.3485101727570922,0.9012476431727784,0.5503594791862298,1.2230607806221265,0.3284538054668826]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"scaled_features\").show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df.randomSplit([0.7,0.3], seed=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 1's are 173 and the number of 0's are 318.0\n",
      "Percentage of 1's are 35.234215885947044\n"
     ]
    }
   ],
   "source": [
    "data_set = float(train_df.select(\"Target\").count())\n",
    "numPositives = train_df.select(\"Target\").where(\"Target == 1\").count()\n",
    "per_one =(float(numPositives)/float(data_set))*100\n",
    "numNegatives = float(data_set - numPositives)\n",
    "print(f\"The number of 1's are {numPositives} and the number of 0's are {numNegatives}\")\n",
    "print(f\"Percentage of 1's are {per_one}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balancing ration is 0.6476578411405295\n"
     ]
    }
   ],
   "source": [
    "#Imbalance of 1's and 0's in Train df\n",
    "BalanceRatio = numNegatives/data_set\n",
    "print(f\"The balancing ration is {BalanceRatio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      classWeights|\n",
      "+------------------+\n",
      "|0.3523421588594705|\n",
      "|0.3523421588594705|\n",
      "|0.3523421588594705|\n",
      "+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.withColumn(\"classWeights\",\n",
    "                               F.when(train_df.Target == 1, BalanceRatio).otherwise(1 - BalanceRatio))\n",
    "train_df.select(\"classWeights\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import ChiSqSelector\n",
    "css = ChiSqSelector(featuresCol='scaled_features',\n",
    "                   outputCol='aspect',\n",
    "                   labelCol=\"Target\",\n",
    "                   fpr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|aspect                                                                                                                                                    |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[0.3554514468699445,0.3259878010202712,0.33426212675591777,0.3485101727570922,0.4506238215863892,0.2751797395931149,0.4076869268740422,0.3284538054668826]|\n",
      "|[0.3554514468699445,0.3259878010202712,0.33426212675591777,0.3485101727570922,0.4506238215863892,0.2751797395931149,0.4076869268740422,0.3284538054668826]|\n",
      "|[0.3554514468699445,0.3259878010202712,0.33426212675591777,0.3485101727570922,0.4506238215863892,0.2751797395931149,0.8153738537480844,0.3284538054668826]|\n",
      "|[0.3554514468699445,0.3259878010202712,0.33426212675591777,0.3485101727570922,0.9012476431727784,0.2751797395931149,0.4076869268740422,0.3284538054668826]|\n",
      "|[0.3554514468699445,0.3259878010202712,0.33426212675591777,0.3485101727570922,0.9012476431727784,0.2751797395931149,0.4076869268740422,0.3284538054668826]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = css.fit(train_df).transform(train_df)\n",
    "test_df = css.fit(test_df).transform(test_df)\n",
    "test_df.select(\"aspect\").show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin structuring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol='Target',\n",
    "                        featuresCol=\"aspect\",\n",
    "                        weightCol=\"classWeights\", \n",
    "                        maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|Target|prediction|\n",
      "+------+----------+\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "|   0.0|       0.0|\n",
      "+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = lr.fit(train_df)\n",
    "predict_train = model.transform(train_df)\n",
    "predict_test = model.transform(test_df)\n",
    "predict_test.select(\"Target\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------------+----------+------------------------------------------+\n",
      "|Target|rawPrediction                         |prediction|probability                               |\n",
      "+------+--------------------------------------+----------+------------------------------------------+\n",
      "|0.0   |[5.734945227861855,-5.734945227861855]|0.0       |[0.9967793467861066,0.0032206532138935413]|\n",
      "|0.0   |[5.734945227861855,-5.734945227861855]|0.0       |[0.9967793467861066,0.0032206532138935413]|\n",
      "|0.0   |[5.685754838632626,-5.685754838632626]|0.0       |[0.9966175096894179,0.003382490310582163] |\n",
      "|0.0   |[5.631926395898063,-5.631926395898063]|0.0       |[0.9964311136047697,0.003568886395230487] |\n",
      "|0.0   |[5.631926395898063,-5.631926395898063]|0.0       |[0.9964311136047697,0.003568886395230487] |\n",
      "|0.0   |[5.631926395898063,-5.631926395898063]|0.0       |[0.9964311136047697,0.003568886395230487] |\n",
      "|0.0   |[5.631926395898063,-5.631926395898063]|0.0       |[0.9964311136047697,0.003568886395230487] |\n",
      "|0.0   |[5.631926395898063,-5.631926395898063]|0.0       |[0.9964311136047697,0.003568886395230487] |\n",
      "|0.0   |[5.631926395898063,-5.631926395898063]|0.0       |[0.9964311136047697,0.003568886395230487] |\n",
      "|0.0   |[5.631926395898063,-5.631926395898063]|0.0       |[0.9964311136047697,0.003568886395230487] |\n",
      "|0.0   |[5.582736006668833,-5.582736006668833]|0.0       |[0.9962518436689102,0.003748156331089889] |\n",
      "|0.0   |[5.582736006668833,-5.582736006668833]|0.0       |[0.9962518436689102,0.003748156331089889] |\n",
      "|0.0   |[5.582736006668833,-5.582736006668833]|0.0       |[0.9962518436689102,0.003748156331089889] |\n",
      "|0.0   |[5.582736006668833,-5.582736006668833]|0.0       |[0.9962518436689102,0.003748156331089889] |\n",
      "|0.0   |[5.035175259503217,-5.035175259503217]|0.0       |[0.9935369843476695,0.006463015652330515] |\n",
      "|0.0   |[5.533545617439604,-5.533545617439604]|0.0       |[0.9960636043385364,0.003936395661463701] |\n",
      "|0.0   |[5.533545617439604,-5.533545617439604]|0.0       |[0.9960636043385364,0.003936395661463701] |\n",
      "|0.0   |[5.533545617439604,-5.533545617439604]|0.0       |[0.9960636043385364,0.003936395661463701] |\n",
      "|0.0   |[5.533545617439604,-5.533545617439604]|0.0       |[0.9960636043385364,0.003936395661463701] |\n",
      "|0.0   |[4.157125421999702,-4.157125421999702]|0.0       |[0.9845887369945987,0.015411263005401361] |\n",
      "+------+--------------------------------------+----------+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',\n",
    "                                          labelCol='Target')\n",
    "predict_test.select(\"Target\",\"rawPrediction\",\"prediction\",\"probability\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC for train is 0.9951285127422111\n"
     ]
    }
   ],
   "source": [
    "print(f\"Area under ROC for train is {evaluator.evaluate(predict_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC for train is 0.9971516463484107\n"
     ]
    }
   ],
   "source": [
    "print(f\"Area under ROC for train is {evaluator.evaluate(predict_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------------------------------------+\n",
      "|Target|prediction|probability                             |\n",
      "+------+----------+----------------------------------------+\n",
      "|1.0   |0.0       |[0.5134524967072315,0.48654750329276863]|\n",
      "|1.0   |0.0       |[0.6822217381697119,0.3177782618302882] |\n",
      "|1.0   |0.0       |[0.8918504063304283,0.10814959366957175]|\n",
      "|0.0   |1.0       |[0.2092372937599848,0.7907627062400152] |\n",
      "|0.0   |1.0       |[0.1102100020861575,0.8897899979138425] |\n",
      "|0.0   |1.0       |[0.33775277443517393,0.6622472255648261]|\n",
      "+------+----------+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test.select(\"Target\",\"prediction\",\"probability\").where(F.col(\"Target\") != F.col(\"prediction\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
